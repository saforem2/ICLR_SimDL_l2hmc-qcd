%
\documentclass{article} % For LaTeX2e
\usepackage{iclr2021_conference,times}

% Optional math commands from https://github.com/goodfeli/dlbook_notation.
\input{math_commands.tex}

\usepackage[unicode,linktocpage=true,breaklinks]{hyperref}% add hypertext capabilities
% \usepackage{url}

\usepackage{xcolor}
\setlength{\marginparwidth}{2cm}
\usepackage{enumitem}
\usepackage{bbm}
\usepackage{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}% Include figure files
\usepackage{dcolumn}% Align table columns on decimal point
\usepackage{bm}% bold math
\usepackage{wrapfig}
\usepackage{subcaption}
\usepackage[normalem]{ulem}
\usepackage[ruled, vlined,inoutnumbered,rightnl]{algorithm2e}
\usepackage{tikz}
\usetikzlibrary{positioning,arrows}
\newcommand{\JCO}[1]{\textcolor{red}{[#1]}}

\hypersetup{
  colorlinks=true,
  urlcolor=green,
  linkcolor=magenta,
  citecolor=cyan,
}

% \usepackage[activate={true,nocompatibility},final,tracking=true,kerning=true,factor=1100,stretch=10,shrink=10]{microtype}
% \usepackage[colorinlistoftodos]{todonotes}
% \usepackage[ruled, vlined,linesnumbered,inoutnumbered,rightnl]{algorithm2e}
% \RequirePackage{lineno}
% \linenumbers\relax % Commence numbering lines

\definecolor{blue1}{HTML}{448aff}
\definecolor{pink1}{HTML}{FA5477}

\newcommand{\mbart}{\textcolor{red}{\bar{m}^{k}}}
\newcommand{\mt}{\textcolor{blue}{m^{k}}}



%\title{Neural Transformations for \\Efficient Topological Mixing}
\title{Deep Learning Hamiltonian Monte Carlo}

% Authors must not appear in the submitted version. They should be hidden
% as long as the \iclrfinalcopy macro remains commented out below.
% Non-anonymous submissions will be rejected without review.

\author{Sam Foreman, Xiao-Yong Jin\& James Osborn\thanks{\hyperref{%
      https://github.com/saforem2/l2hmc-qcd
   }{https://github.com/saforem2/l2hmc-qcd} \\
   Leadership Computing Facility\\
   Argonne National Laboratory\\
   Lemont, IL 60439
   \texttt{\{foremans,xjin,\}@anl.gov},%
   \texttt{\{osborn\}@alcf.anl.gov}\\
}}

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

% \iclrfinalcopy % Uncomment for camera-ready version, but NOT for submission.
\begin{document}


\maketitle

\begin{abstract}
   %We propose a generalized version of the L2HMC algorithm~\citep{levy2017},
   We generalize the Hamiltonian Monte Carlo algorithm with a stack of neural network layers,
   and evaluate its ability to sample from
   different topologies in a two-dimensional lattice gauge theory.
   %
   %In particular, 
   We demonstrate that our model is able to successfully mix between modes of different topology,
   significantly reducing the computational cost required to generate independent gauge configurations.
\end{abstract}

% \section{\label{sec:introduction}Introduction}
% \color{red}{TODO:\@ Complete introduction}\color{black}
%\section{TODO}
%\begin{enumerate}
%   \item Instead of using a time step to vary the network inputs, we use completely different networks for each leapfrog
%      step in our trajectory \textcolor{blue}{\(\ast\)}. \marginpar{\textcolor{blue}{\(\ast\) WIP}}
%   \item Explain that ``instead of using \(\|x^{\prime}-x\|\), in \(\mathcal{L}_{\theta}\) we use \ldots''
%   \item Remove ``During training we maintain a buffer of \(M=2048\)\ldots'' from \Secref{sec:main_contributions}
%   %\item Combine \((5.)\), \((6.)\), \((7.)\) in \Secref{sec:main_contributions}
%   \item Remove \Eqref{eq:wilsonaction}, combine with \(p_{t}(x)\) at the end of \Secref{sec:annealing}, and move
%      inline. \textcolor{blue}{\(\ast\)}\marginpar{\textcolor{blue}{\(\ast\) WIP}}
%   \item Explain \(\mathcal{Q}_{\mathbb{Z}}\) is a physical quantity (winding number), explain we want to maximize
%      difference but need continuous variable for training, hence \(\mathcal{Q}_{\mathbb{R}}\)
%   \item Change notation for lattice gauge theory, \(\varphi_{\mu}(x)\rightarrow x_{\mu}(n)\) to be consistent with
%      \Secref{sec:l2hmc}.\marginpar{\textcolor{red}{\(\checkmark\) done}}
%   \item Emphasize efforts on interpretability, analogy with understanding intermediate layers/structures in
%      conv/fully-connected network.
%  \item Don't need to include details about annealing schedule (save space).
%  \item Instead of splitx figure, re-draw network diagram showing inputs/outputs and various layers. ``Generalized leapfrog''.
%  \item \textbf{``Leapfrog layer''}: Show network diagram for a single leapfrog layer, indicate that each leapfrog step uses a separate leapfrog layer, explain how "Full-step position update, etc." are a single leapfrog layer with  index \(k\).
%  
%\end{enumerate}
%%
\section{\label{sec:introduction}Introduction}
In \citet{levy2017}, the authors propose the Learning to Hamiltonian Monte Carlo (L2HMC) algorithm, and demonstrate
its ability to outperform traditional Hamiltonian Monte Carlo (HMC) on a variety of %two-dimensional %% they have higher DOF
target
distributions.
%
%In particular, 
They show that the trained L2HMC sampler is capable of mixing between modes by exploring regions of phase space which are %typically
inaccessible with traditional HMC.
%
In this paper, we propose a generalized sampler using a deep neural network that is self trained to propose new Markov Chain states,
which is made exact with the help of Metropolis-Hastings \citep{zbMATH03349185} algorithm.
We target our Deep Learning Hamiltonian Monte Carlo (DLHMC) algorithm to simulating lattice gauge theories,
where state-of-the-art simulations have billions of degrees of freedom and run on supercomputers with thousands of nodes,
yet suffers exponential slowing downs when approaching continuum physics \citep{schaefer2009investigating,cossu2018testing}.
%The ability to mix between isolated modes of a multi-modal target distribution is highly desirable for MCMC simulations of lattice gauge theory, which are known to become prohibitively expensive as we increase the resolution of our simulations \cite{kschaefer2009investigating,cossu2018testing}.

\section{\label{sec:main_contributions}Main Contributions}
%\begin{enumerate}
%   \item
We propose the DLHMC algorithm as a generalized HMC algorithm,
      using a stack of distinct neural network layers replacing consecutive leapfrog steps.
      %that uses different networks (with different step
      %sizes) for each distinct leapfrog step.
      %
      Each distinct neural network layer, carrying a discrete index \(k = 0, 1, \ldots, N_{\mathrm{LF}}-1\) for $N_{\mathrm{LF}}$
      leapfrog layers, performs the
      augmented leapfrog equations, (\Eqref{eq:new_momentum_update}, \Eqref{eq:new_position_update}), indicating that
      these functions are parametrized by different neural networks.
      %
      
%   \item
%We propose a modified loss function specifically designed for our physical system,
%encouraging the tunneling of topological properties.
      %
%      \begin{equation}
%          \mathcal{L}(\theta) = \mathbb{E}_{p(\xi)}{%
%              \left[ \, -\delta(\xi^{\prime}, \xi) \, A(\xi^{\prime}|\xi)\,\right],\quad\text{with}\quad%
%          \delta(\xi^{\prime}, \xi) \equiv
%      {\left(\mathcal{Q}_{\mathbb{R}}^{\prime}-\mathcal{Q}_{\mathbb{R}}\right)}^{2}
%          }
%      \end{equation}
      %
%      where \(\mathcal{Q}_{\mathbb{R}}\in\mathbb{R}\) is the real-valued topological charge, defined in \Secref{sec:lattice_gauge_theory}.
      %
%     We evaluate this loss at the end of each trajectory during training, and use the gradient information to update
%      the weights \(\theta\) parameterizing the auxiliary functions \(s^{k}_{i}, t^{k}_{i}, q^{k}_{i}\), (\(i \in\{x, v\}\), \(k \in \{0, 1, \ldots, N_{\mathrm{LF}}\}\))
%      introduced in the augmented leapfrog updates in \Secref{sec:method}.
      %
   %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
   
%   \item
We apply the proposed method to a \(1+1\)-dimensional \(U(1)\) lattice gauge theory defined on a
      square lattice with periodic boundary conditions.
We specifically designed a loss function for our physical system,
encouraging the tunneling of topological properties.
      We see a significant reduction in the
      computational cost using DLHMC, as measured by the integrated autocorrelation time of the topological charge
      \(\tau_{\mathrm{int}}^{\mathcal{Q}}\).
      %
      We compare our results to traditional HMC across a variety of trajectory lengths and coupling constants
      \(\beta\), and show that our trained model consistently outperforms traditional HMC (see
      \Figref{fig:autocorr_vs_beta}).

We find that the efficiency in tunneling topological sectors of our trained DLHMC sampler
is explained by the behavior of the physical system as it passes through the deep neural network.
%\end{enumerate}
%
\section{\label{sec:related_work}Related Work:}
Recently, there has been a growing interest in applying generative machine learning techniques to build smarter, more efficient scientific simulations.
%
Following the development of the RealNVP \citep{dinhRealNVP} architecture, there have been many proposed techniques that aim to take advantage of its invertible structure.
%
In particular, simulations in lattice gauge theory and lattice QCD stand to benefit tremendously from this new approach, as evidenced by the rapidly-growing body of work in this direction 
\citep{%
   albergo2019flow,albergo2021introduction,favoni2020lattice,medvidovic2020generative,neklyudov2020orbital,
   neklyudov2020involutive, li2020neural,boyda2020sampling,kanwar2020equivariant,toth2019hamiltonian,
   hoffman2019neutra,wehenkel2020you,pasarica2010adaptively, dinhRealNVP,tanaka2017towards,
   rezende2020normalizing%cossu2018testing,
}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\label{sec:method}DLHMC algorithm}
%
We provide a review of the generic Hamiltonian Monte Carlo (HMC) algorithm and set up some of the relevant notation in
\Secref{subsec:HMC}.
%
For simulating a system, $x$, using a theoretically given probability density $p(x)$ with likely intractable normalization,
we augment the Markov chain state as
\(\xi = (x, v, d)\) with target distribution \(p(\xi) = p(x, v, d) = p(x) p(v) p(d)\).
The conjugate momentum $v$ typically used in HMC algorithms has a known and easy to sample distribution.
%
The binary direction variable, as introduced in L2HMC~\citep{levy2017},
\(d\in\mathcal{U}(+,-)\), %which is resampled following each Metropolis-Hastings accept/reject step, and can be
%interpreted as determining
denoting the ``direction'' (forward/backward) of our update.
%
%The key modification of the L2HMC algorithm is the introduction of six auxiliary functions \(s_{i}, t_{i}, q_{i}\) for \(i
%\in \{x, v\}\) into the leapfrog updates (\Secref{subsec:leapfroghmc}), which are parameterized by weights \(\theta\) in a neural network.
%

DLHMC algorithm further generalize the leapfrog steps in L2HMC using individual neural networks.
Each leapfrog step in DLHMC is a layer of the deep neural network that transforms the input $\xi_k=(x_k,v_k,d_k)$, for the $k$-th layer,
to output $(x''_k,v''_k,d_k)$, where $d_k$ stays constant choosing either the forward or backward leapfrog layer.
Subsequently the $k+1$-th layer uses $\xi_{k+1}=(x''_k,v''_k,d_k)$ is its input.
For simplicity, we consider the forward \(d=+1\) direction, and introduce the notation:
%
\begin{align}
   v^{\prime}_{k} &\equiv \Gamma^{+}_{k}(v_{k};\zeta_{v_{k}})
   = v_{k}\odot \exp{\left(\tfrac{\varepsilon^{k}_{v}}{2}s_{v}^{k}(\zeta_{v_{k}})\right)} -
   \tfrac{\varepsilon^{k}_{v}}{2}{\left[\partial_{x}S(x_{k})\odot\exp{\left(\varepsilon^{k}_{v} q_{v}^{k}(\zeta_{v_{k}})\right)}
      +t_{v}^{k}(\zeta_{v_{k}})\right]},\label{eq:new_momentum_update}\\
   x^{\prime}_{k} &\equiv \Lambda^{+}(x_{k};\zeta_{x_{k}})
   = x_{k}\odot\exp(\varepsilon^{k}_{x} s^{k}_{x}(\zeta_{x_{k}}))
   + \varepsilon^{k}_{x}\left[v^{\prime}_{k}\odot\exp(\varepsilon^{k}_{x} q^{k}_{x}(\zeta_{x_{k}}))
         + t^{k}_{x}(\zeta_{x_{k}})\right]\label{eq:new_position_update}
\end{align}
%
where: (1.) \(\zeta_{v_{k}} = (x_{k}, \partial_{x}S(x_{k}))\) and \(\zeta_{x_{k}} = (x_{k}, v_{k})\) denote the (\(x\),
\(v\) respectively) networks' inputs\footnote{%
 The $v$ network is independent of the variables being updated,
 the $x$ network will be made independent with the mask $m^k$.};
  (2.) we indicate the direction of the update by the superscript \(\pm\) on \(\Gamma^{\pm}_{k},
\Lambda^{\pm}_{k}\); (3.) \(k\in\{0,1,\ldots,N_{\mathrm{LF}}\}\) denotes the current leapfrog step along the trajectory.
%
We include in \Figref{fig:network} an illustration of the network architecture of the $k$-th leapfrog layer
used for the updates in \Eqref{eq:new_momentum_update} and \Eqref{eq:new_position_update}.
%
\begin{figure}[htpb]
   \centering
   \includegraphics[width=0.8\textwidth]{figures/network11.pdf}
   \caption{\label{fig:network}Illustration of the network architecture used in \Eqref{eq:new_momentum_update} and \Eqref{eq:new_position_update}.}
\end{figure}

Using this notation, we can write a complete leapfrog update (in the forward \(d=+1\) direction)\footnote{%
   To obtain the expression for the reverse direction, we can invert each of the
   \(\Gamma^{-}\equiv{\left(\Gamma^{+}\right)}^{-1}, \Lambda^{-}\equiv{\left(\Lambda^{+}\right)}^{-1}\) functions, and
   perform the updates in the opposite order.
} as:
%
\begin{enumerate}
   \item Half-step momentum update:%
      \hspace{29pt}\(%
         v^{\prime}_{k} = \Gamma^{+}_{k}(v_{k};\zeta_{v_{k}})%
   \)
   \item Full-step half-position update:\footnote{%
         By this we mean we are performing a complete update on one-half of the indices of \(x\) (determined by
         \(\mt\odot x\)), followed by an analogous update of the complementary indices, \(\mbart\odot x\).
   }
      \hspace{14pt} \(%
         x^{\prime}_{k} = \mbart\odot x_{k} + \mt\odot \Lambda^{+}_{k}(x_{k};\zeta_{x_{k}})
   \)
   \item Full-step half-position update:%
      \hspace{21pt} \(%
         x^{\prime\prime}_{k} = \mbart\odot\Lambda^{+}_{k}(x^{\prime}_{k};\zeta_{x^{\prime}_{k}}) + \mt\odot x^{\prime}_{k}
   \)
   \item Half-step momentum update:%
      \hspace{25pt} \(%
         v^{\prime\prime}_{k} = \Gamma_{k}^{+}(v^{\prime}_{k}; \zeta_{v^{\prime}_{k}})
   \)
\end{enumerate}
%
Collectively, we refer to this series of updates as a single \emph{leapfrog layer}, which performs a single update \(\xi\rightarrow\xi^{\prime}\).
%
Note that in order to keep our update reversible, we've split the \(x\) update into two sub-updates by
introducing a binary mask \(\mbart = \mathbbm{1} - \mt\) that updates half of the components of \(x\) sequentially.
%

As in HMC, we form a complete trajectory by performing \(N_{\mathrm{LF}}\) leapfrog steps in sequence, followed by a Metropolis-Hastings accept/reject step as described in \Eqref{eq:mhcriteria}.
%
However, unlike in the expression for HMC, we must take into account the overall Jacobian factor from the update
\(\xi\rightarrow\xi^{\prime}\), which can be easily computed as \(\left|\tfrac{\partial v^{\prime\prime}_{k}}{\partial
   v_{k}}\right| = \exp{\left(\tfrac{1}{2}{\varepsilon^{k}_{v} s^{k}_{v}(\zeta_{v_{k}})}\right)}\),
   \(\left|\tfrac{\partial x^{\prime\prime}_{k}}{\partial x_{k}}\right| = \exp{\left(\varepsilon^{k}_{x} s^{k}_{x}(\zeta_{x_{k}})\right)}\).
where we keep the Jacobian factor for individual degree of freedom tractable.
%
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{\label{sec:lattice_gauge_theory}U(1) Lattice Gauge Theory}
%
\begin{wrapfigure}{r}{0.2\textwidth}
      \centering
      \includegraphics[width=0.2\textwidth]{figures/plaq_tikz.pdf}
      \caption{\label{fig:plaquette}Plaquette}%, \(P\)}
\end{wrapfigure}
Lattice gauge theory is one formulation of quantum field theories with gauge fields, eg. Quantum Electrodynamics (QED) and Quantum Chromodynamics.
It is the predominant method that can be computed numerically, and widely used for simulating subatomic particles and nuclei.
Here we describe the U(1) gauge (QED), and apply our DLHMC in 2 dimensional systems.
Let \(U_{\mu}(n) = e^{i x_{\mu}(n)} \in U(1)\), with \(x_{\mu}(n) \in [-\pi,\pi]\) denote the \emph{link
variables}, where \(x_{\mu}(n)\) is the link oriented in the \(\hat{\mu}\)-direction located at the site
\(n\).
%
We can write our target distribution in terms of the Wilson action \(S_{\beta}(x)\) as
%
\begin{equation}
   p_{t}(x) = \frac{1}{Z}e^{-\gamma_{t} S_{\beta}(x)},\quad\text{with}\quad S_{\beta}(x) = \beta \sum_{P}1 - \cos(x_{P})
   \label{eq:wilsonaction}
\end{equation}
%
where $Z$ is the intractable normalization;
\(\gamma_{t}\) is a scaling factor (\(\|\gamma_{t}\|<1\)) slowly annealed during training (\Secref{sec:annealing});
\(x_{P} \equiv x_{\mu}(n) + x_{\nu}(n+\hat{\mu}) - x_{\mu}(n+\hat{\nu}) -x_{\nu}(n)\) is a combination of link
variables around the \(1\times1\) elementary plaquette, shown in \Figref{fig:plaquette}; and the sum is over all
such plaquettes on the lattice.
%
Here, \(\beta = 2 / g_{0}^{2}\) is a coupling constant and \(\beta\rightarrow\infty\) recovers the continuum limit of the theory. 
%

Physically, each lattice configuration has its topological charge, \(\mathcal{Q}_{\mathbb{Z}}\in\mathbb{Z}\), defined as
%
\begin{equation}
      \mathcal{Q}_{\mathbb{Z}}(x) \equiv \frac{1}{2\pi}\sum_{P}\left\lfloor x_{P}\right\rfloor,
   \quad\text{where}\quad \left\lfloor x_{P}\right\rfloor = x_{P} -
   2\pi\left\lfloor\frac{x_{P}+\pi}{2\pi}\right\rfloor.
   \label{eq:intcharge}
\end{equation}
%
Current methods are severely limited in their ability to mix between different topologies, a phenomenon known as topological freezing,
when simulation approaches the continuum limit.
%
For this reason, we wish to construct a loss function that encourages our sampler to explore different topological sectors.
%
In order to do so, we introduce a continuous version of the topological charge, \(\mathcal{Q}_{\mathbb{R}}\in\mathbb{R}\), by replacing the projection in \Eqref{eq:intcharge} to give:
%
\begin{equation}
    \mathcal{Q}_{\mathbb{R}} \equiv \frac{1}{2\pi}\sum_{P}\sin(x_{P}).
    \label{eq:sincharge}
\end{equation}
% [it's always real value]
%This quantity has the advantage of being real-valued to help prevent numerical instability during training.
This quantity has the advantage of being continuously differentiable, which is important for training the deep neural network.
%
Our loss function is then defined as
%
\begin{equation}
   \mathcal{L}(\theta) = \mathbb{E}_{p(\xi)}{%
      \left[\,-\delta(\xi^{\prime}, \xi) \, A(\xi^{\prime}|\xi)\,\right]
   }
\end{equation}
%
where \(\delta(\xi^{\prime}, \xi) \equiv {\left(\mathcal{Q}_{\mathbb{R}}(x^{\prime}) - \mathcal{Q}_{\mathbb{R}}(x)\right)}^{2}\) and \(A(\xi^{\prime}|\xi)\) is given in \Eqref{eq:mhcriteria}.
%
%

\section{\label{sec:results}Results}
%
We apply our DLHMC algorithm with
the training procedure in \Secref{sec:algorithm} and the annealing schedule from \Secref{sec:annealing}
to the 2D U(1) gauge theory with parameters gradually approaching the continuum limit.
%We are able to train our sampler for some fixed number of training steps and then run inference on the trained model.
We then run inference to generate the Markov chain using the trained model and compare its efficiency with HMC.
%
%For this experiment, we used a batch size of $M=2048$, [PLEASE MORE DEEP LEARNING PARAMETERS]
%We trained our models using the supercomputer ThetaGPU at Argonne Leadership Facility.  We used [ NODE-HOURS A100 TENSORFLOW HOROVOD].
%
We trained our models using Horovod \citep{horovod2018sergeev} with TensorFlow \citep{tensorflow2015-whitepaper} on the ThetaGPU supercomputer at the Argonne Leadership Computing Facility.
%
%supercomputer ThetaGPU at Argonne Leadership Computing Facility using Horovod + TensorFlow for data-parallel training.
%
A typical training run on 1 node (\(8\times\) NVIDIA A100 GPUs) using a batch size \(M=2048\), hidden layer shapes \(=\left[256, 256, 256\right]\) for each of the \(N_{\mathrm{LF}}=10\) leapfrog layers, on a \(16\times16\) lattice, for \(5\times10^{5}\) training steps takes roughly \(24\) hours to complete.
%
%During training we maintain a buffer of \(M=2048\) chains which are updated in parallel.
%

%We evaluate the loss function and update our weights accordingly at the end of each trajectory prior to performing the Metropolis-Hastings accept/reject step.
%

%During inference, we record the values of quantities of interest and compare them to the results obtained from running inference using generic HMC.
%

\begin{wrapfigure}{r}{0.4\textwidth}
   \centering
      \centering
      \includegraphics[width=0.4\textwidth]{figures/autocorr_vs_beta_blue_2120.pdf}
      \caption{\label{fig:autocorr_vs_beta}Estimate of the integrated autocorrelation time
      \(\tau_{\mathrm{int}}^{\mathcal{Q}_{\mathbb{R}}}\) vs \(\beta\), scaled by \(N_{\mathrm{LF}}\) to account for
   different trajectory lengths.}
         % for HMC (black dashed line), trained model (solid blue line).}
\end{wrapfigure}
To measure the improvement of our model, we evaluate the integrated autocorrelation time of the topological charge which can be interpreted roughly as the number of trajectories needed (on average) before an independent sample is drawn.
%
In order to more accurately capture the computational effort per step between the two approaches we scale our estimate of the integrated autocorrelation time by the number of leapfrog steps as \(N_{\mathrm{LF}}\tau\).
We can see in \Figref{fig:autocorr_vs_beta}, that the trained model consistently outperforms generic HMC across \(\beta = 2, 3, \ldots, 7\).
%
To ensure the validity of our results, each trained run was compared to multiple HMC runs across a range of \(N_{\mathrm{LF}}\) and \(\varepsilon\) values.
%
We see in \Figref{fig:topological_freezing} that HMC remains stuck at a particular value of \(\mathcal{Q}_{\mathbb{Z}}\) for large sections of the simulation, whereas the trained sampler rapidly jumps between values.
%
In order to better understand the mechanism driving this improved behavior, we evaluate different quantities at each of the intermediate leapfrog layers \(k=0, 1, 2, \ldots, N_{\mathrm{LF}}\) during the trajectory.
%
We can see in \Figref{fig:plaqsf} and \Figref{fig:hwf} that our sampler exhibits an increase in energy during the first half of the trajectory before returning back to its original value.
%
We believe that this ability to vary the energy during the trajectory helps the sampler to overcome energy barriers between topological sectors whereas HMC remains stuck.
%
%By introducing the scaling \(N_{\mathrm{LF}} \tau_{\mathrm{int}}\) we more accurately capture the computational effort per step when comparing the two approaches.
%

%If we think of the average plaquette as being an energy density, we can see in \Figref{fig:plaqsf}, \Figref{fig:hwf} that our sampler experiences a gradual increase in energy during the first half of the trajectory before decreasing back to its original value at the end.
%
%
%
\begin{figure}[htpb]
   \centering
   %
   \begin{subfigure}{\textwidth}
      \centering
      \includegraphics[width=0.8\textwidth]{figures/topological_freezing_anl_blue_wide.pdf}
      \caption{\label{fig:topological_freezing}Topological charge \(\mathcal{Q}_{\mathbb{Z}}\) vs MC
      step for both HMC (black line) and the trained model (blue line).}% for HMC (black line), and trained model (blue line)}
   \end{subfigure}
   %
   \hfill
   %
   \begin{subfigure}{0.32\textwidth}
      \centering
      \includegraphics[width=0.8\textwidth]{figures/plaqsf_1758.pdf}
      \caption{\label{fig:plaqsf}Change in the average plaquette, \(\langle x_{P}-x_{P}^{*}\rangle\) at intermediate leapfrog layers.}
   \end{subfigure}
   \hfill
   \begin{subfigure}{0.32\textwidth}
      \centering
      \includegraphics[width=0.8\textwidth]{figures/sinQf_1755.pdf}
      \caption{\label{fig:sinQf}The real-valued topological charge, \(\mathcal{Q}_{\mathbb{R}}\) at intermediate leapfrog layers.}%
   \end{subfigure}
   %
   \hfill
   \begin{subfigure}{0.32\textwidth}
      \centering
      \includegraphics[width=0.8\textwidth]{figures/extras/hwf.pdf}
      \caption{\label{fig:hwf}The readjusted energy, \(\mathcal{H}-\sum\log|\mathcal{J}|\), of the model at intermediate leapfrog layers.}
   \end{subfigure}
\end{figure}
%

\subsubsection*{Acknowledgments}
This research was supported by the Exascale Computing Project (17-SC-20-SC), a collaborative effort of the U.S. Department of Energy Office of Science and the National Nuclear Security Administration.
This research was performed using resources of the Argonne Leadership Computing Facility (ALCF), which is a DOE Office of Science User
Facility supported under Contract DE\_AC02--06CH11357. 
%
This work describes objective technical results and analysis.
%
Any subjective views or opinions that might be expressed in the work do not necessarily represent the views of the U.S.
DOE or the United States Government.
%

Results presented in this research were obtained using the Python \citep{van1995python}, programming language and its many data science libraries \citep{matplotlib,numpyharris2020array,tensorflow2015-whitepaper,seaborn_michael_waskom_2017_883859,ipython4160251}

\bibliography{iclr2021_conference}
\bibliographystyle{iclr2021_conference}

\appendix
\section{Appendix}
%
\subsection{\label{subsec:HMC}Hamiltonian Monte Carlo (HMC)}
%
The Hamiltonian Monte Carlo algorithm is a widely used technique that allows us to sample from an analytically known
target distribution \(p(x)\) by constructing a chain of states \(\{x^{(0)}, x^{(1)}, \ldots, x^{(n)}\}\), such that
\(x^{(n)}\sim p(x)\) in the limit \(n\rightarrow\infty\).
%
For our purposes, we assume that our target distribution can be expressed as a Boltzmann distribution, \(p(x) =
\tfrac{1}{\mathcal{Z}} e^{-S(x)}\propto e^{-S(x)}\), where \(S(x)\) is the \emph{action} of our theory, and
\(\mathcal{Z}\) is a normalization factor (the partition function).
%
In this case, HMC begins by augmenting the state space with a fictitious momentum variable \(v\), normally
distributed independently of \(x\), i.e.\ \(v\sim\mathcal{N}(0, \mathbbm{1})\).
%
Our joint distribution can then be written as \(%
   p(x, v) = p(x) p(v) \propto e^{-S(x)} e^{-\frac{1}{2}v^{T}v} = e^{-\mathcal{H}(x, v)}
\), where \(\mathcal{H}(x, v)\) is the Hamiltonian of the joint (x, v) system.
%
This system obeys Hamilton's equations: % 
\(\dot{x} = \frac{\partial\mathcal{H}}{\partial v}\), \(\dot{v} = -\frac{\partial H}{\partial x}\), which can be 
numerically integrated using the leapfrog integrator along iso-probability contours of \(\mathcal{H} = \text{const.}\).
%
Explicitly, for a step size \(\varepsilon\) and initial state \(\xi = (x, v)\), the leapfrog integrator generates a
proposal configuration \(\xi^{\prime} \equiv (x^{\prime}, v^{\prime})\) by performing the following series of updates: 
%
\subsection{\label{subsec:leapfroghmc}Leapfrog Update}
%
\begin{enumerate}
   \item Half-step momentum update: \hspace{12pt}\(%
      v^{1/2} \equiv v{\left(t+\frac{\varepsilon}{2}\right)} = v-\frac{\varepsilon}{2}\partial_{x}S(x)
   \)
   \item Full-step position update: \hspace{36pt}\(%
      x^{\prime} \equiv x(t+\varepsilon) = x + \varepsilon v^{1/2}
   \)
   \item Half-step momentum update:
      \hspace{18pt} \(%
         v^{\prime} \equiv v(t+\varepsilon) = v^{1/2} - \frac{\varepsilon}{2}\partial_{x} S(x^{\prime})
   \)
\end{enumerate}
%
We can then construct a complete \emph{trajectory} of length \(\lambda = \varepsilon N_{\mathrm{LF}}\) by
performing \(N_{\mathrm{LF}}\) leapfrog steps in sequence.
%
At the end of our trajectory, we either accept or reject the proposal configuration according to the Metropolis-Hastings
acceptance criteria,
%
\begin{equation}
   x_{i+1} =
   \begin{cases}%
      x^{\prime} &\mbox{with probability } A(\xi^{\prime}|\xi) \\
      x &\mbox{with probability } (1 - A(\xi^{\prime}|\xi)), \quad\text{and}\quad%
         A(\xi^{\prime}|\xi) = \min\left\{%
            1, \frac{p(\xi^{\prime})}{p(\xi)}\left|\frac{\partial{\xi^{\prime}}}{\partial\xi^{T}}\right|%
         \right\}.
   \end{cases}
   \label{eq:mhcriteria}
\end{equation}
%
The generic leapfrog integrator is known to be symplectic (conserves energy), so the Jacobian factor reduces to
\(\left|\frac{\partial\xi^{\prime}}{\partial\xi^{T}}\right| = 1\). 
%
\section{\label{sec:annealing}Annealing Schedule}
%
To help our sampler overcome the large energy barriers between isolated modes, we introduce an \emph{annealing schedule}
during the training phase (\(N\) training steps) \({\{\gamma_{t}\}}_{t=0}^{N} = \{\gamma_{0}, \gamma_{1}, \ldots,
\gamma_{N-1}, \gamma_{N}\}\), where \(\gamma_{0} < \gamma_{1} < \ldots < \gamma_{N} \equiv 1\), \(\gamma_{t+1} -
\gamma_{t} \ll 1\).
%
Note that we are free to vary \(\gamma\) during the initial training phase as long as we recover the true distribution
with \(\gamma \equiv 1\) at the end of training and evaluate our trained model without this factor.
%
Explicitly, for \(\gamma_{t} < 1\) this rescaling factor helps to reduce the height of the energy barriers, making it
easier for our sampler to explore previously inaccessible regions of the phase space.
%
In terms of this additional annealing schedule, our target distribution picks up an additional index \(t\) to represent
our progress through the training phase, which can be written explicitly as 
%
\begin{equation}
   p_{t}(x)\propto e^{-\gamma_{t} S(x)},\quad\text{for}\quad t=0, 1, \ldots, N
   \label{eq:targetannealing}
\end{equation}
%
\section{\label{sec:algorithm}Training Algorithm}
%
\begin{algorithm}[htpb]%
   \SetAlgoLined%
   \SetAlgoVlined%
   \SetKwProg{Fn}{def}{\string:}{}%
   \SetKwFunction{Range}{range}%
   \SetKwFor{For}{\color{blue}\textbf{\texttt{for}}}{\string:}{}\color{black}%
   \SetKwIF{If}{ElseIf}{Else}{if}{:}{elif}{else:}{}%
   \SetKwFor{While}{while}{:}{fintq}%
   \SetKwInOut{Input}{\color{red}{\textbf{\texttt{input}}}\color{black}}%
   \SetKwInOut{Output}{\color{red}{\textbf{\texttt{output}}}\color{black}}%
   \AlgoDontDisplayBlockMarkers\SetAlgoNoEnd%
   \DontPrintSemicolon%
   \caption{\label{alg:training_algorithm}Training procedure}%
   \Input{%
         %(1.) \texttt{Target distribution,} \(p_{t}(x)\propto e^{-\beta_{t} U(x)}\)
         %(2.) \texttt{Loss function}, \(\mathcal{L}_{\theta}(\xi^{\prime},\xi,
         %   A (\xi^{\prime}|\xi))\)
         %(3.) \texttt{Learning rate schedule}, \({\{\alpha_{t}\}}_{t=0}^{N_{\mathrm{train}}}\)
         %(4.) \texttt{Annealing schedule}, \({\{\gamma_{t}\}}_{t=0}^{N_{\mathrm{train}}}\)
         %(5.) \texttt{Batch of initial states}, \(x\)
      % {}\\
      \begin{enumerate}
         \item \texttt{Target distribution,} \(p_{t}(x)\propto e^{-\beta_{t} U(x)}\)
         \item \texttt{Loss function}, \(\mathcal{L}_{\theta}(\xi^{\prime},\xi,
            A(\xi^{\prime}|\xi))\)
         \item \texttt{Learning rate schedule}, \({\{\alpha_{t}\}}_{t=0}^{N_{\mathrm{train}}}\)
         \item \texttt{Annealing schedule}, \({\{\gamma_{t}\}}_{t=0}^{N_{\mathrm{train}}}\)
         \item \texttt{Batch of initial states}, \(x\)
      \end{enumerate}
   }%
   \texttt{Initialize weights} \(\theta\)\;
   % {}\;
   \For{\(0 \leq t < N_{\mathrm{train}}\)}{%
      % {}\;
      \texttt{update:} \(p_{t}(x)\propto e^{-\beta_{t}U(x)}\)\;
      \texttt{resample:} \(v\sim\mathcal{N}(0, \mathbbm{1})\)\;
      \texttt{resample:} \(d\sim\mathcal{U}(+,-)\)\;
      \texttt{construct:} \(\xi \equiv (x, v, d)\)\;
      % {}\;
      \For{\(0 \leq \ell < N_{\mathrm{LF}}\)}{%
         \texttt{propose:} \(\xi_{\ell}^{\prime}\leftarrow\mathbf{FL}_{\ell}^{\pm}\xi_{\ell}\)
      }
      \texttt{compute:} \(A(\xi^{\prime}|\xi) =%
      \min\left\{1,\frac{p(\xi^{\prime})}{p(\xi)}\left|\frac{\partial%
      \xi^{\prime}}{\partial \xi^{T}}\right|\right\}\)\;
      % {}\;
      \texttt{update:} \(\mathcal{L}\leftarrow \mathcal{L}_{\theta}(\xi^{\prime},\xi,%
      A(\xi^{\prime}|\xi))\)\;
      % {}\;
      \texttt{backprop:} \(\theta\ \leftarrow\ \theta-\alpha_t \nabla_{\theta} \mathcal{L}\)\;
      % {}\;
      \texttt{assign:} \(x_{t+1} \leftarrow
      \begin{cases}
         x^{\prime} &\mbox{with probability } A(\xi^{\prime}|\xi) \\
         x &\mbox{with probability } (1 - A(\xi^{\prime}|\xi)).%
      \end{cases}%
      \)\;
   }\;
\end{algorithm}%
%
%\section{\label{sec:hyperparameters}Hyperparameters}
%\begin{table}[]
%\begin{tabular}{|l|l|l|l|l|l|l|l|l|l|}
%\hline
% & \(N_{\mathrm{LF}}\) & \(\beta_{0}\) & \(\beta_{1}\) & train steps & hidden layer sizes & activation function & dropout probability & batch norm layer &  \\ \hline
%1 &  &  &  &  &  &  &  &  &  \\ \hline
%  &  &  &  &  &  &  &  &  &  \\ \hline
%  &  &  &  &  &  &  &  &  &  \\ \hline
%  &  &  &  &  &  &  &  &  &  \\ \hline
%  &  &  &  &  &  &  &  &  &  \\ \hline
%  &  &  &  &  &  &  &  &  &  \\ \hline
%  &  &  &  &  &  &  &  &  &  \\ \hline
%\end{tabular}
%\end{table}
%
\end{document}